server.port=8090
logging.config=classpath:logback.xml

spring.kafka.bootstrap-servers=127.0.0.1:9092
# 消息重发的次数
spring.kafka.producer.retries= 0
# 一个批次可以使用的内存大小
spring.kafka.producer.batch-size=16384
# 设置生产者内存缓冲区的大小
spring.kafka.producer.buffer-memory=33554432
# 键的序列化方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
# 值的序列化方式
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=all
#事务Id
spring.kafka.producer.transaction-id-prefix=happygenuibi-Transaction

#该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：
spring.kafka.consumer.auto-offset-reset=earliest
#是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
spring.kafka.consumer.enable-auto-commit=false
#自动提交的时间间隔 在spring boot 2.X 版本是值的类型为Duration 需要符合特定的格式，如1S,1M,2H,5D
#spring.kafka.consumer.auto-commit-interval=1S
#键的反序列化方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#值的反序列化方式
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

#手工ack，调用ack后立刻提交offset
spring.kafka.listener.ack-mode=manual_immediate
#容器运行的线程数
spring.kafka.listener.concurrency=4